{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0de73be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "in_data = loadmat('face_emotion_data.mat')\n",
    "#loadmat() loads a matlab workspace into a python dictionary, where the names of the variables are the keys \n",
    "#in the dictionary.  To see what variables are loaded, uncomment the line below: \n",
    "#print([key for key in in_data])\n",
    "\n",
    "y = in_data['y']\n",
    "X = in_data['X']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a87f6e",
   "metadata": {},
   "source": [
    "Classifier a.) Truncated SVD\n",
    "\n",
    "Known result from lecture: \n",
    "\n",
    "w_min = sum(i=1, i=p) 1/sigma_i * v_i * (u_i^T * d)\n",
    "\n",
    "Truncate as follows: \n",
    "\n",
    "w_min_r = sum(i=1, i=r) 1/sigma_i * v_i * (u_i^T * d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0f8408f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 8 equal sized slices\n",
    "\n",
    "X_slices = np.split(X,8)\n",
    "y_slices = np.split(y,8)\n",
    "\n",
    "\n",
    "# split slices into 6-slice stacks\n",
    "from itertools import combinations\n",
    "\n",
    "X_stacks = []\n",
    "y_stacks = []\n",
    "X_holdouts = []\n",
    "y_holdouts = []\n",
    "\n",
    "# use combinations to get all possible 6-slice combinations\n",
    "for combo in combinations(range(8), 6):\n",
    "    X_stack = np.vstack([X_slices[i] for i in combo])\n",
    "    y_stack = np.vstack([y_slices[i] for i in combo])\n",
    "    X_stacks.append(X_stack)\n",
    "    y_stacks.append(y_stack)\n",
    "    \n",
    "    # designate the X_holdouts and y_holdouts as the slices not assigned to each stack\n",
    "    holdout_indices = [i for i in range(8) if i not in combo]\n",
    "    X_holdout = np.vstack([X_slices[i] for i in holdout_indices])\n",
    "    y_holdout = np.vstack([y_slices[i] for i in holdout_indices])\n",
    "    X_holdouts.append(X_holdout)\n",
    "    y_holdouts.append(y_holdout)\n",
    "\n",
    "# convert to nparrays for better processing\n",
    "X_stacks = np.array(X_stacks)\n",
    "y_stacks = np.array(y_stacks)\n",
    "X_holdouts = np.array(X_holdouts)\n",
    "y_holdouts = np.array(y_holdouts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4a49e253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 9)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stacks[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ec897298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifier a.) Truncated SVD\n",
    "\n",
    "U,s,VT = np.linalg.svd(X, full_matrices = False)\n",
    "UT = U.T\n",
    "V = VT.T\n",
    "s\n",
    "\n",
    "# Create a diagonal matrix with singular values s\n",
    "sigma = np.diag(s)\n",
    "rows = 9\n",
    "cols = 9\n",
    "sigma = np.zeros_like(np.zeros((rows, cols)));\n",
    "np.fill_diagonal(sigma, s)\n",
    "\n",
    "# Known result from lecture: w_min = V Sigma^-1 U_tilde^T y\n",
    "# Truncate as follows: \n",
    "# w_min_r = V Sigma_r^-1 U_tilde^T y\n",
    "# where U_tilde represents the component of U remaining after Economic SVD is performed.\n",
    "# and Sigma_r^-1 represents the inverse of the Sigma matrix truncated to a specific row r\n",
    "\n",
    "# this function computes a list of w_min's for the all values of r from 1 to rank(input)\n",
    "def w_min_rs(X_, y_):\n",
    "    U_,s_,VT_ = np.linalg.svd(X_, full_matrices = False)\n",
    "    UT_ = U_.T\n",
    "    V_ = VT_.T\n",
    "    sigma_ = np.diag(s_)\n",
    "    rows_ = 9\n",
    "    cols_ = 9\n",
    "    sigma_ = np.zeros_like(np.zeros((rows_, cols_)));\n",
    "    np.fill_diagonal(sigma_, s_)\n",
    "    w_min_rs_ = []\n",
    "    \n",
    "    for i in range(np.linalg.matrix_rank(X_)):\n",
    "        # truncate sigma\n",
    "        sigma_inv_ = np.linalg.inv(sigma_)\n",
    "        sigma_i_ = sigma_inv_ * (np.arange(sigma_inv_.shape[0]) < i+1)[:, None]\n",
    "        w_min_rs_.append(V_ @ sigma_i_ @ UT_ @ y_)\n",
    "        \n",
    "    return w_min_rs_\n",
    "\n",
    "# this function estimates the error rate some training and test data\n",
    "# it also returns the best value of r\n",
    "def estimate_error(X_train, y_train, X_test, y_test, regularization_type):\n",
    "    \n",
    "    # compute the w_mins with the function above\n",
    "    w_min_rs_ = w_min_rs(X_train, y_train)\n",
    "    \n",
    "    error_rates = []\n",
    "    \n",
    "    # for each value of r\n",
    "    if(regularization_type == \"truncated_SVD\"):\n",
    "        \n",
    "        for w_min_r in w_min_rs_:\n",
    "\n",
    "            # compute y_pred by using the w_min_r value on X_test\n",
    "            y_pred = X_test @ w_min_r\n",
    "\n",
    "            # compute the proportion of errors for that value of r\n",
    "            # this is a binary classifier so use sign of predictions, and take mean\n",
    "            error = np.mean(np.sign(y_pred) != np.sign(y_test))\n",
    "\n",
    "            error_rates.append(error)\n",
    "    \n",
    "    # for each value of r\n",
    "    # for each value of r\n",
    "    elif(regularization_type == \"ridge_regression\"):\n",
    "        \n",
    "        lambdas_ = [2**i for i in range(-1, 5)]\n",
    "        w_min_lambdas_ = ridge_regression(X_train, y_train, lambdas_)\n",
    "        \n",
    "        for w_min_lambda in w_min_lambdas_:\n",
    "\n",
    "            # compute y_pred by using the w_min_lambda value on X_test\n",
    "            y_pred = X_test @ w_min_lambda\n",
    "\n",
    "            # compute the proportion of errors for that value of lambda\n",
    "            # this is a binary classifier so use sign of predictions, and take mean\n",
    "            error = np.mean(np.sign(y_pred) != np.sign(y_test))\n",
    "\n",
    "            error_rates.append(error)\n",
    "    \n",
    "    # find the (first) value of r that minimizes error\n",
    "    best_r = np.argmin(error_rates)\n",
    "    \n",
    "    # find the error rate corresponding to the optimal value of r\n",
    "    best_error_rate = error_rates[best_r]\n",
    "    \n",
    "    return best_r, best_error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each X_stack (6-long), 28 total :\n",
    "    # -select the best value of r\n",
    "    # -use the w corresponding to the best value of r to predict the labels of holdout set 1\n",
    "    # -compute the % error of these predicted labels\n",
    "    # function estimate_error above does all of this\n",
    "    # run estimate_error with each X_stack, y_stack, X_holdout 1, y_holdout 1\n",
    "    \n",
    "    # -use the w corresponding to the best value of r to predict the labels of holdout set 2\n",
    "    # -compute the % error of these predicted labels\n",
    "    # function estimate_error above does all of this\n",
    "    # run estimate_error with each X_stack, y_stack, X_holdout 2, y_holdout 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e9401779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated SVD: \n",
      "Error rate average over both holdout sets: 0.03459821428571429\n"
     ]
    }
   ],
   "source": [
    "error_rates_holdout1_SVD = []\n",
    "error_rates_holdout2_SVD = []\n",
    "\n",
    "# for each X_stack (6-long, 28 total):\n",
    "for i in range(len(X_stacks)):\n",
    "    # append the computed error rate at the optimal value of r\n",
    "    error_rates_holdout1_SVD.append(estimate_error(X_stacks[i], y_stacks[i], X_holdouts[i][:16], y_holdouts[i][:16], \"truncated_SVD\")[1])\n",
    "    error_rates_holdout2_SVD.append(estimate_error(X_stacks[i], y_stacks[i], X_holdouts[i][16:], y_holdouts[i][16:], \"truncated_SVD\")[1])\n",
    "    \n",
    "error_rates_overall_SVD = np.concatenate([error_rates_holdout1_SVD, error_rates_holdout2_SVD])\n",
    "print(f\"Truncated SVD: \\nError rate average over both holdout sets: {np.mean(error_rates_overall_SVD)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "812d72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "1b586ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier b.) - Ridge Regression\n",
    "# several of the functions above can be re-used so I will call them as needed\n",
    "\n",
    "# Also, apply result from Lecture video 4.1:\n",
    "# w_min = V (Sigma^2 + lambda*I)^-1 @ Sigma @ U^T @ y\n",
    "# This result is derived from taking the expression:\n",
    "# w_min = (A^T A + lambda*I)^-1 @ A^T @ y\n",
    "# and plugging in the SVD for A, A = U @ Sigma @ V^T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "20c5deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X_, y_, lambdas_):\n",
    "    \n",
    "    U_, s_, VT_ = np.linalg.svd(X_, full_matrices=False)\n",
    "    V_ = VT_.T\n",
    "    sigma_ = np.diag(s_)\n",
    "    dimension_ = len(s_)\n",
    "    w_min_lambdas_ = []\n",
    "    \n",
    "    for lambda_ in lambdas_:\n",
    "        w_min_lambda = V_ @ np.linalg.inv(sigma_**2 + lambda_ * np.identity(dimension_)) @ sigma_ @ U_.T @ y_\n",
    "        w_min_lambdas_.append(w_min_lambda)\n",
    "        \n",
    "    return w_min_lambdas_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "fed71152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: \n",
      "Error rate average over both holdout sets: 0.03571428571428571\n"
     ]
    }
   ],
   "source": [
    "error_rates_holdout1_ridge = []\n",
    "error_rates_holdout2_ridge = []\n",
    "\n",
    "# for each X_stack (6-long, 28 total):\n",
    "for i in range(len(X_stacks)):\n",
    "    # append the computed error rate at the optimal value of r\n",
    "    error_rates_holdout1_ridge.append(estimate_error(X_stacks[i], y_stacks[i], X_holdouts[i][:16], y_holdouts[i][:16], \"ridge_regression\")[1])\n",
    "    error_rates_holdout2_ridge.append(estimate_error(X_stacks[i], y_stacks[i], X_holdouts[i][16:], y_holdouts[i][16:], \"ridge_regression\")[1])\n",
    "    \n",
    "error_rates_overall_ridge = np.concatenate([error_rates_holdout1_ridge, error_rates_holdout2_ridge])\n",
    "print(f\"Ridge Regression: \\nError rate average over both holdout sets: {np.mean(error_rates_overall_ridge)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "486fa87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.03125)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_error(X_stacks[1], y_stacks[1], X_holdouts[1], y_holdouts[1], \"ridge_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e262036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
